#+TITLE: 緑本 in Python (2)
#+OPTIONS: num:nil
#+PROPERTY: header-args:ipython  :session ch03 :exports both

[[http://hosho.ees.hokudai.ac.jp/~kubo/ce/IwanamiBook.html][久保拓弥, データ解析のための統計モデリング入門, 岩波書店, 2012. （通称緑本）]] を Python で書いていく練習の 2 回目は，第 3 章の一般化線形モデル (GLM) です。くわしくは [[https://github.com/tnoda/midorihon-in-python]]


* 第3章 一般化線形モデル (GLM)

#+begin_src ipython
  %matplotlib inline
  import matplotlib.pyplot as plt
  plt.style.use('ggplot')
  from numpy.random import randn
  import numpy as np
  from pandas import Series, DataFrame
  import pandas as pd
  pd.__version__
#+end_src

#+RESULTS:
: u'0.17.0'


** 3.2 観測されたデータを調べる


*** pd.read_csv()

データのファイル名を ~data3a.csv~ とすると， Python では

#+BEGIN_SRC ipython
  d = pd.read_csv('data3a.csv')
#+END_SRC

#+RESULTS:

と命じるだけでファイルを読み込んで，その内容を格納した Pandas データフレイムに ~d~ という名前がつけられます。 ob-ipython で ~d~ とすると全 100 個体ぶんのデータが表示されます。

#+BEGIN_SRC ipython
  d
#+END_SRC

#+RESULTS:
#+begin_example
     y      x  f
0    6   8.31  C
1    6   9.44  C
2    6   9.50  C
3   12   9.07  C
4   10  10.16  C
5    4   8.32  C
6    9  10.61  C
7    9  10.06  C
8    9   9.93  C
9   11  10.43  C
10   6  10.36  C
11  10  10.15  C
12   6  10.92  C
13  10   8.85  C
14  11   9.42  C
15   8  11.11  C
16   3   8.02  C
17   8  11.93  C
18   5   8.55  C
19   5   7.19  C
20   4   9.83  C
21  11  10.79  C
22   5   8.89  C
23  10  10.09  C
24   6  11.63  C
25   6  10.21  C
26   7   9.45  C
27   9  10.44  C
28   3   9.44  C
29  10  10.48  C
..  ..    ... ..
70  10  10.54  T
71   8  11.30  T
72   8  12.40  T
73   7  10.18  T
74   5   9.53  T
75   6  10.24  T
76   8  11.76  T
77   9   9.52  T
78   9  10.40  T
79   6   9.96  T
80   7  10.30  T
81  10  11.54  T
82   6   9.42  T
83  11  11.28  T
84  11   9.73  T
85  11  10.78  T
86   5  10.21  T
87   6  10.51  T
88   4  10.73  T
89   5   8.85  T
90   6  11.20  T
91   5   9.86  T
92   8  11.54  T
93   5  10.03  T
94   9  11.88  T
95   8   9.15  T
96   6   8.52  T
97   8  10.24  T
98   7  10.86  T
99   9   9.97  T

[100 rows x 3 columns]
#+end_example

最終行に表示されているように， ~d~ には全 100 個体ぶんのデータが 100 行 3 列の行列のような形式で格納されているように見えます。このデータでは，最初の列 y には種子数， x には個体の体サイズ， f には施肥処理の値が入っています。


*** astype('category)

この d の列ごとにデータを表示させてみましょう。 

#+BEGIN_SRC ipython
  d.x
#+END_SRC

#+RESULTS:
#+begin_example
0      8.31
1      9.44
2      9.50
3      9.07
4     10.16
5      8.32
6     10.61
7     10.06
8      9.93
9     10.43
10    10.36
11    10.15
12    10.92
13     8.85
14     9.42
15    11.11
16     8.02
17    11.93
18     8.55
19     7.19
20     9.83
21    10.79
22     8.89
23    10.09
24    11.63
25    10.21
26     9.45
27    10.44
28     9.44
29    10.48
      ...  
70    10.54
71    11.30
72    12.40
73    10.18
74     9.53
75    10.24
76    11.76
77     9.52
78    10.40
79     9.96
80    10.30
81    11.54
82     9.42
83    11.28
84     9.73
85    10.78
86    10.21
87    10.51
88    10.73
89     8.85
90    11.20
91     9.86
92    11.54
93    10.03
94    11.88
95     9.15
96     8.52
97    10.24
98    10.86
99     9.97
Name: x, dtype: float64
#+end_example


#+BEGIN_SRC ipython
  d.x
#+END_SRC

#+RESULTS:
#+begin_example
0      8.31
1      9.44
2      9.50
3      9.07
4     10.16
5      8.32
6     10.61
7     10.06
8      9.93
9     10.43
10    10.36
11    10.15
12    10.92
13     8.85
14     9.42
15    11.11
16     8.02
17    11.93
18     8.55
19     7.19
20     9.83
21    10.79
22     8.89
23    10.09
24    11.63
25    10.21
26     9.45
27    10.44
28     9.44
29    10.48
      ...  
70    10.54
71    11.30
72    12.40
73    10.18
74     9.53
75    10.24
76    11.76
77     9.52
78    10.40
79     9.96
80    10.30
81    11.54
82     9.42
83    11.28
84     9.73
85    10.78
86    10.21
87    10.51
88    10.73
89     8.85
90    11.20
91     9.86
92    11.54
93    10.03
94    11.88
95     9.15
96     8.52
97    10.24
98    10.86
99     9.97
Name: x, dtype: float64
#+end_example

#+BEGIN_SRC ipython
  d.f
#+END_SRC

#+RESULTS:
#+begin_example
0     C
1     C
2     C
3     C
4     C
5     C
6     C
7     C
8     C
9     C
10    C
11    C
12    C
13    C
14    C
15    C
16    C
17    C
18    C
19    C
20    C
21    C
22    C
23    C
24    C
25    C
26    C
27    C
28    C
29    C
     ..
70    T
71    T
72    T
73    T
74    T
75    T
76    T
77    T
78    T
79    T
80    T
81    T
82    T
83    T
84    T
85    T
86    T
87    T
88    T
89    T
90    T
91    T
92    T
93    T
94    T
95    T
96    T
97    T
98    T
99    T
Name: f, dtype: object
#+end_example

施肥処理の有無をあらわす f 列は R とは違って文字列 (object) としてデータが格納されています。これを R の因子型 (factor) と同様のカテゴリー型にするには ~astype()~ メソッドを利用します。

#+BEGIN_SRC ipython
  d.f.astype('category')
#+END_SRC

#+RESULTS:
#+begin_example
0     C
1     C
2     C
3     C
4     C
5     C
6     C
7     C
8     C
9     C
10    C
11    C
12    C
13    C
14    C
15    C
16    C
17    C
18    C
19    C
20    C
21    C
22    C
23    C
24    C
25    C
26    C
27    C
28    C
29    C
     ..
70    T
71    T
72    T
73    T
74    T
75    T
76    T
77    T
78    T
79    T
80    T
81    T
82    T
83    T
84    T
85    T
86    T
87    T
88    T
89    T
90    T
91    T
92    T
93    T
94    T
95    T
96    T
97    T
98    T
99    T
Name: f, dtype: category
Categories (2, object): [C, T]
#+end_example

この Python の出力では，最終行の ~Categories~ の行で ~f~ 列内の水準を示しています。

#+BEGIN_SRC ipython
  d.f.astype('category').cat.ordered
#+END_SRC

#+RESULTS:
: False

カテゴリー型の水準の値には順番がある場合と無い場合があり，この場合はありません。 Pandas のカテゴリー型データにはデフォルトでは順番がありません。順番が必要な場合は ~astype()~ で明示的に指定します。

#+BEGIN_SRC ipython
  d.f = d.f.astype('category', ordered=True)
  d.f.cat.ordered
#+END_SRC

#+RESULTS:
: True

#+BEGIN_SRC ipython
d.f
#+END_SRC

#+RESULTS:
#+begin_example
0     C
1     C
2     C
3     C
4     C
5     C
6     C
7     C
8     C
9     C
10    C
11    C
12    C
13    C
14    C
15    C
16    C
17    C
18    C
19    C
20    C
21    C
22    C
23    C
24    C
25    C
26    C
27    C
28    C
29    C
     ..
70    T
71    T
72    T
73    T
74    T
75    T
76    T
77    T
78    T
79    T
80    T
81    T
82    T
83    T
84    T
85    T
86    T
87    T
88    T
89    T
90    T
91    T
92    T
93    T
94    T
95    T
96    T
97    T
98    T
99    T
Name: f, dtype: category
Categories (2, object): [C < T]
#+end_example

順番のあるカテゴリー型列を表示させた場合，最終行の ~Categories~ のところに ~[C < T]~ と 不等号が入ります。


*** info(), dtypes

Pandas データフレームの ~info()~ メソッドを使うと，あるデータフレームにどういう型のデータが含まれているかを調べられます。

#+BEGIN_SRC ipython :results output
  d.info()
#+END_SRC

#+RESULTS:
: <class 'pandas.core.frame.DataFrame'>
: Int64Index: 100 entries, 0 to 99
: Data columns (total 3 columns):
: y    100 non-null int64
: x    100 non-null float64
: f    100 non-null category
: dtypes: category(1), float64(1), int64(1)
: memory usage: 2.5 KB

また，型名だけで十分であれば ~dtypes~ を使うこともできます。

#+BEGIN_SRC ipython
  d.dtypes
#+END_SRC

#+RESULTS:
: y       int64
: x     float64
: f    category
: dtype: object


*** describe()

さて， Pandas データフレームの ~describe()~ メソッドを使って，この ~d~ と名づけられたデータフレームの概要を調べてみましょう。

#+BEGIN_SRC ipython
  d.describe()
#+END_SRC

#+RESULTS:
:                 y           x
: count  100.000000  100.000000
: mean     7.830000   10.089100
: std      2.624881    1.008049
: min      2.000000    7.190000
: 25%      6.000000    9.427500
: 50%      8.000000   10.155000
: 75%     10.000000   10.685000
: max     15.000000   12.400000

このように ~describe()~ を用いると各列の要約を表示することができます。 ~f~ 列の要約は全体の要約では表示されていないので，このような場合は， ~f~ 列単独で ~describe()~ します。

#+BEGIN_SRC ipython
  d.f.describe()
#+END_SRC

#+RESULTS:
: count     100
: unique      2
: top         T
: freq       50
: Name: f, dtype: object

どのレベルの要素がいくつあるのかは ~describe()~ では分からないため， ~value_count()~ で数えます。

#+BEGIN_SRC ipython
  d.f.value_counts()
#+END_SRC

#+RESULTS:
: T    50
: C    50
: dtype: int64


** 3.3 統計モデリングの前にデータを図示する

観測データに余計な手を加えないで，データ全体をよく見るには ~plot()~ 関数などを使うと便利でしょう。

*** plot(kind='scatter', ...)

#+BEGIN_SRC ipython :file ./figs/fig_3-2.png
  fig = plt.figure()
  ax = fig.add_subplot(1, 1, 1)
  labels = ['C', 'T']
  dfs = [d[d['f'] == x] for x in labels]
  colors = ['Red', 'Blue']
  for i in range(2):
      dfs[i].plot(kind='scatter', x='x', y='y', color=colors[i], label=labels[i], ax=ax)
#+END_SRC

#+RESULTS:
[[file:./figs/fig_3-2.png]]


複数のグループを一枚の散布図に重ねたいときには，同じ ~ax~ に対して何度も ~plot()~ します。

*** boxplot(by=...)

箱ひげ図を描きたいときには ~boxplot()~ メソッドを使います。

#+BEGIN_SRC ipython :file ./figs/fig_3-3.png
  d[['y', 'f']].boxplot(by='f')
#+END_SRC

#+RESULTS:
[[file:./figs/fig_3-3.png]]



** 3.4.2 ポアソン回帰の統計モデル - あてはめとあてはまりの良さ

*** statsmodels.api.GLM(), patsy.dmatrices()

Python ではたいへんお手軽に GLM のあてはめができるようになっていて，

#+BEGIN_SRC ipython
  import statsmodels.api as sm
  from patsy import dmatrices
  from statsmodels.genmod.families.family import Poisson

  y, X = dmatrices('y ~ x', data=d, return_type='dataframe')
  fit = sm.GLM(y, X, family=Poisson()).fit()
#+END_SRC

#+RESULTS:

と指定すれば，切片 $\beta_1$ と傾き $\beta_2$ の最尤推定値が得られます。 ~sm.GLM()~ 関数で指定している内容は次のようになります。

+ モデル式
  - R 風のモデル式を使うために patsy の ~dmatrices()~ 関数を使っています
  - ~y ~ x~ というのがそれです
+ 確率分布の指定
  - ~family=Poisson()~ でポアソン分布を指定しています
  - ~Poisson()~ のデフォルトのリンク関数は対数リンク関数です
+ データフレームの指定
  - ~data=d~ で指定します

*** summary()

では，この例題の推定結果を格納している ~fit~ を調べてみましょう。

#+BEGIN_SRC ipython
  fit.summary()
#+END_SRC

#+RESULTS:
#+begin_example
<class 'statsmodels.iolib.summary.Summary'>
"""
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                      y   No. Observations:                  100
Model:                            GLM   Df Residuals:                       98
Model Family:                 Poisson   Df Model:                            1
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -235.39
Date:                Wed, 11 Nov 2015   Deviance:                       84.993
Time:                        18:08:07   Pearson chi2:                     83.8
No. Iterations:                     7                                         
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      1.2917      0.364      3.552      0.000         0.579     2.005
x              0.0757      0.036      2.125      0.034         0.006     0.145
==============================================================================
"""
#+end_example

下段に注目してみましょう。この部分の読みかたを説明してみます。 ~Intercept~ は切片 $\beta_1$ に，説明変数 ~x~ の係数は傾き $\beta_2$ に対応しています。 ~coef~ は推定値のことで，結果出力を見ると，最尤推定値は $\hat{\beta_1} = 1.29$ と $\hat{\beta_2} = 0.0757$ であるとわかります。 ~std err~ はパラメーターの標準誤差の推定値です。標準誤差 (standard error, SE) とは，この場合には推定値 $\hat{\beta_1}$, と ${\hat{\beta_2}$ の「ばらつき」を標準偏差であらわしたものです。

次にあらわれす ~z~ は z 値と呼ばれる統計量であり最尤推定値を SE で除した値です。これによって， Wald 信頼区間というものを構成でき，推定値たちがゼロから十分に離れているかどうかの粗い目安になります。この z 値は Wald 統計量 (Wald statistics) とも呼ばれています。

最後の ~P>|z|~ は，この場合に限定して言えば，平均が z 値の絶対値であり，標準偏差が 1 の正規分布におけるマイナス無限大からゼロまでの値をとる確率の 2 倍です。この確率が大きいほど z 値がゼロに近くなり，推定値 $\hat{\beta_1}$ や $\hat{\beta_2}$ がゼロに近いことを表現するひとつの方法です。

*** GLMResults.llm, GLMResults.df_model

Python を使ってこのモデルの最大対数尤度を評価するには，

#+BEGIN_SRC ipython
  fit.llf
#+END_SRC

#+RESULTS:
: -235.38625076986077

とすればよく，最大対数尤度は -234.5 くらいとわかります。モデルの自由度 (degree of freedom) は

#+BEGIN_SRC ipython
  fit.df_model
#+END_SRC

#+RESULTS:
: 1

とすればよいです。ただし，切片 (intercept) はこの ~df_model~ には含まれないことに注意してください。


** 3.4.3 ポアソン回帰モデルによる予測

このポアソン回帰の推定結果を使って，さまざまな体サイズ $x$ における平均種子数 $\lambda$ の予測 (prediction) をしてみましょう。個体の体サイズ $x$ の関数である平均種子数 $\lambda$ の関数に推定値 ${\hat{\beta_1}, \hat{\beta_2}}$ を代入した関数

\begin{equation}
  \lambda = exp(1.29+0.0757x)
\end{equation}

を使って Python で図示してみましょう。

*** GLMResults.predict()

#+BEGIN_SRC ipython :file ./figs/fig_3-7.png
  fig = plt.figure()
  ax = fig.add_subplot(1, 1, 1)
  labels = ['C', 'T']
  dfs = [d[d['f'] == x] for x in labels]
  colors = ['Red', 'Blue']
  for i in range(2):
      dfs[i].plot(kind='scatter', x='x', y='y', color=colors[i], ax=ax)
  yy = fit.predict(X)
  df = DataFrame({'x': X.x, 'y': yy}).sort_index(by='x')
  plt.plot(df.x, df.y, 'g-')
#+END_SRC

#+RESULTS:
[[file:./figs/fig_3-7.png]]


** 3.5 説明変数が因子型の統計モデル

説明変数が因子型であっても，ダミー変数を準備するといった工夫も必要なく，モデル式を指定できます。

#+BEGIN_SRC ipython
  y, X = dmatrices('y ~ C(f)', data=d, return_type='dataframe')
  fit_f = sm.GLM(y, X, dat=d, family=Poisson()).fit()
  fit_f.summary()
#+END_SRC

#+RESULTS:
#+begin_example
<class 'statsmodels.iolib.summary.Summary'>
"""
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                      y   No. Observations:                  100
Model:                            GLM   Df Residuals:                       98
Model Family:                 Poisson   Df Model:                            1
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -237.63
Date:                Wed, 11 Nov 2015   Deviance:                       89.475
Time:                        18:08:07   Pearson chi2:                     87.1
No. Iterations:                     7                                         
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      2.0516      0.051     40.463      0.000         1.952     2.151
C(f)[T.T]      0.0128      0.071      0.179      0.858        -0.127     0.153
==============================================================================
"""
#+end_example


パラメーターの推定値 (coef セクション) の出漁をみると，施肥効果 $f_i$ の係数の名前は ~C(f)[T.T]~ となっていて，これは説明変数 $f_i$ が ~T~ 水準でとる値を示しています。説明変数 $f_i$ には ~C~ と ~T~ の 2 水準が設定されています。 ~GLM~ 関数は最初の水準の値を 0 とおき，これを基準にして ~T~ のような他の水準の値を推定します。もし個体 $i$ の $f_i$ が ~C~ ならば

\begin{equation}
\lambda_i = exp(2.05+0) = exp(2.05) = 7.77
\end{equation}

であり，もし ~T~ ならば

\begin{equation}
\lambda_i = exp(2.05+0.0128) = exp(2.0628) = 7.87
\end{equation}

となります。このように，推定されたモデルでは「肥料をやると平均種子数がほんの少しだけ増える」と予測しています。

このモデルで最大対数尤度は

#+BEGIN_SRC ipython
  fit_f.llf
#+END_SRC

#+RESULTS:
: -237.62725696068682

となり，サイズ $x_i$ だけのモデルの最大対数尤度 -235.4 より小さく，あてはまりが悪くなっています。


** 3.6 説明変数が数量型 + 因子型の統計モデル

今度は，個体の体サイズ $$x_i$$ と施肥効果 $$f_i$$ の複数の説明変数を同時にくみこんだ統計モデルを作ってみましょう。 Python の ~GLM()~ 関数による推定計算は特に何も指示しないで，モデル式の部分を ~x + C(f)~ とするだけで適切に処理してくれます。

#+BEGIN_SRC ipython
  y, X = dmatrices('y ~ x + C(f)', data=d, return_type='dataframe')
  fit_all = sm.GLM(y, X, dat=d, family=Poisson()).fit()
#+END_SRC

#+RESULTS:

結果を格納している ~fit_all~ の出力を見てみましょう。

#+BEGIN_SRC ipython
  fit_all.summary()
#+END_SRC

#+RESULTS:
#+begin_example
<class 'statsmodels.iolib.summary.Summary'>
"""
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                      y   No. Observations:                  100
Model:                            GLM   Df Residuals:                       97
Model Family:                 Poisson   Df Model:                            2
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -235.29
Date:                Wed, 11 Nov 2015   Deviance:                       84.808
Time:                        18:08:07   Pearson chi2:                     83.8
No. Iterations:                     7                                         
==============================================================================
                 coef    std err          z      P>|z|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      1.2631      0.370      3.417      0.001         0.539     1.988
C(f)[T.T]     -0.0320      0.074     -0.430      0.667        -0.178     0.114
x              0.0801      0.037      2.162      0.031         0.007     0.153
==============================================================================
"""
#+end_example

この結果出力をみると，前の節では肥料の効果 ~C(f)[T.T]~ がプラスであったのに，このモデルではマイナスだと推定されています。肥料の効果についてはいよいよわからなくなりました。

このモデルで最大対数尤度は，

#+BEGIN_SRC ipython
  fit_all.llf
#+END_SRC

#+RESULTS:
: -235.29371924249367

となり， $$x_i$$ だけのモデルの最大対数尤度 (-235.4) と比較すると少しだけあてはまりが良くなっています。


** 3.8 この章のまとめ

+ Python を使うとデータを要約したいろいろな統計量を調べられる
+ GLM は確率分布・リンク関数・線形予測子を指定する統計モデルであり， statsmodels の ~GLM()~ 関数でパラメータ推定できる
+ GLM では数量型・因子型の両タイプの説明変数を同時に組み込んでよい

